{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "8d9186bb39863f90c20f0aa8318ab8aceae11a779a0992ea39dd3f05ec3a81ec"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agrKBXs5KHwP",
        "outputId": "77cd2f06-4817-4b3c-b78c-81b8d792de98"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan  8 04:42:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.89       Driver Version: 460.89       CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce RTX 208... WDDM  | 00000000:03:00.0  On |                  N/A |\n",
            "|  0%   33C    P8    20W / 300W |   1066MiB / 11264MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A       708    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A      1272    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      2584    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
            "|    0   N/A  N/A      2812    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A      3096    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      3248    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A      7612    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
            "|    0   N/A  N/A      8040    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      8068    C+G   ...s\\Win64\\EpicWebHelper.exe    N/A      |\n",
            "|    0   N/A  N/A      8456    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
            "|    0   N/A  N/A     10328    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A     10344    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     11048    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     11268    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Imports\n",
        "import transformers\n",
        "from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import re\n",
        "from transformers import AdamW\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from pylab import rcParams\n",
        "\n",
        "from torch import nn, optim\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8epKT-KXwR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import XLNetTokenizer, XLNetModel, XLNetForSequenceClassification\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
        "from nlp import load_dataset\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import datasets\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Set random seet and define device\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Read in dataset\n",
        "df = pd.read_csv(r'E:\\Datasets\\Tweet Sentiment Analysis\\training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Drop unneeded columns\n",
        "df = df.drop([1,2,3,4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    #text = re.sub(r\"[A-Za-z0-9]+\", ' ', text)\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
        "    text = re.sub(r\"[^a-zA-z.!?'0-9@#-]\", ' ', text)\n",
        "    text = re.sub('\\t', ' ',  text)\n",
        "    text = re.sub(r\" +\", ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Clean the tweets\n",
        "df[5] = df[5].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Fix up sentiment labels\n",
        "def sentiment2label(sentiment):\n",
        "    if sentiment == 4:\n",
        "        return 1\n",
        "    else :\n",
        "        return 0\n",
        "\n",
        "df[0] = df[0].apply(sentiment2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Rename columns\n",
        "df.columns = ['sentiment', 'tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Split data in to train, test, and val\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=101)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Save dataframes to csv\n",
        "df_train.to_csv(r'E:\\Datasets\\Tweet Sentiment Analysis\\train.csv')\n",
        "df_test.to_csv(r'E:\\Datasets\\Tweet Sentiment Analysis\\test.csv')\n",
        "df_val.to_csv(r'E:\\Datasets\\Tweet Sentiment Analysis\\val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initialize tokenizer\n",
        "PRE_TRAINED_MODEL_NAME = r'E:\\Models\\bert-large-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ]
        }
      ],
      "source": [
        "#Set special token variables\n",
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 102 0 100\n"
          ]
        }
      ],
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Set max input length\n",
        "max_input_length = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define tokenize_and_cut function which takes in text and outputs tokens truncated for the max length\n",
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define data fields\n",
        "from torchtext import data\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define torchtext datasets\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = 'E:\\\\Datasets\\\\Tweet Sentiment Analysis\\\\',\n",
        "                                        train = 'train.csv',\n",
        "                                        validation = 'val.csv',\n",
        "                                        test = 'test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = [(None, None), ('l', LABEL), ('t', TEXT)],\n",
        "                                        skip_header = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'0': 0, '1': 1})\n"
          ]
        }
      ],
      "source": [
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(LABEL.vocab.stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 1280000\nNumber of validation examples: 160000\nNumber of testing examples: 160000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'l': '1', 't': [1030, 6583, 12171, 27172, 4283, 2005, 3582, 2860, 2860, 2860, 2860, 2860, 2860, 2860, 2860]}\n"
          ]
        }
      ],
      "source": [
        "print(vars(train_data.examples[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'wanna', 'go', 'act', 'my', 'shoe', 'size', 'an', 'have', 'a', 'water', 'fight']\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[4])['t'])\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Set the batch size and define the device and data iterators\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    sort=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initialize Bert\n",
        "bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define BERTGRUSentiment for regression\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define hyperparameters\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define binary_accuracy function\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define train function\n",
        "def train(model, iterator, optimizer, criterion, scaler):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            predictions = model(batch.t).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.l)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.l)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        \n",
        "        scaler.step(optimizer)\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        scaler.update()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            \n",
        "            with autocast():\n",
        "\n",
        "                predictions = model(batch.t).squeeze(1)\n",
        "                \n",
        "                loss = criterion(predictions, batch.l)\n",
        "                \n",
        "                acc = binary_accuracy(predictions, batch.l)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 20m 23s\n",
            "\tTrain Loss: 0.304 | Train Acc: 86.79%\n",
            "\t Val. Loss: 0.366 |  Val. Acc: 84.22%\n",
            "Epoch: 02 | Epoch Time: 19m 26s\n",
            "\tTrain Loss: 0.301 | Train Acc: 86.90%\n",
            "\t Val. Loss: 0.370 |  Val. Acc: 84.20%\n",
            "Epoch: 03 | Epoch Time: 19m 4s\n",
            "\tTrain Loss: 0.299 | Train Acc: 87.04%\n",
            "\t Val. Loss: 0.372 |  Val. Acc: 84.35%\n",
            "Epoch: 04 | Epoch Time: 19m 16s\n",
            "\tTrain Loss: 0.297 | Train Acc: 87.16%\n",
            "\t Val. Loss: 0.372 |  Val. Acc: 84.34%\n",
            "Epoch: 05 | Epoch Time: 19m 17s\n",
            "\tTrain Loss: 0.295 | Train Acc: 87.23%\n",
            "\t Val. Loss: 0.366 |  Val. Acc: 84.30%\n",
            "Epoch: 06 | Epoch Time: 19m 9s\n",
            "\tTrain Loss: 0.293 | Train Acc: 87.34%\n",
            "\t Val. Loss: 0.371 |  Val. Acc: 84.10%\n",
            "Epoch: 07 | Epoch Time: 18m 59s\n",
            "\tTrain Loss: 0.291 | Train Acc: 87.45%\n",
            "\t Val. Loss: 0.371 |  Val. Acc: 84.21%\n",
            "Epoch: 08 | Epoch Time: 19m 0s\n",
            "\tTrain Loss: 0.290 | Train Acc: 87.51%\n",
            "\t Val. Loss: 0.377 |  Val. Acc: 84.16%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-49-3ed380d04c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-36-b3a42d0fdf69>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, scaler)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Run the training loop\n",
        "#Use accuracy as metric\n",
        "#Baseline is 50% since there are an equal amount of positive and negative tweets\n",
        "N_EPOCHS = 50\n",
        "best_valid_loss = float('inf')\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, scaler)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'E:/Datasets/Tweet Sentiment Analysis/models/bert_model2')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#Load saved model - max 85% accuracy both test and val sets\n",
        "model.load_state_dict(torch.load('E:/Datasets/Tweet Sentiment Analysis/models/bert_model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_iterator' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-31-2921c05d2ff4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Calculate test loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_iterator' is not defined"
          ]
        }
      ],
      "source": [
        "#Calculate test loss and accuracy\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define predict_sentiment function that takes the trained model, tokenizer, and the sentence to analyze\n",
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    #sentence = clean_text(sentence)\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    positive = round(prediction.item() * 100, 2)\n",
        "    negative = round(100 - positive, 2)\n",
        "    print(f'Positive: {positive}%')\n",
        "    print(f'Negative: {negative}%')\n",
        "    print('-'*25)\n",
        "    if positive >= 55:\n",
        "        print('This tweet is positive!')\n",
        "    elif positive <= 45:\n",
        "        print('This tweet is negative!')\n",
        "    else:\n",
        "        print('This tweet is neutral.')\n",
        "\n",
        "    print('-'*25)\n",
        "    print(f'Text = {sentence}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweet = \"\"\"We must end all federal executions and abolish the death penalty. In a world of incredible violence, the state should not be involved in premeditated murder.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive: 2.62%\nNegative: 97.38%\n-------------------------\nThis tweet is negative!\n-------------------------\nText = We must end all federal executions and abolish the death penalty. In a world of incredible violence, the state should not be involved in premeditated murder.\n\n"
          ]
        }
      ],
      "source": [
        "predict_sentiment(model, tokenizer, tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load train and test dataframes for tree and linear models\n",
        "df = pd.read_csv(r'E:\\Datasets\\Tweet Sentiment Analysis\\train.csv').drop('Unnamed: 0', axis=1)\n",
        "df_test = pd.read_csv(r'E:\\Datasets\\Tweet Sentiment Analysis\\test.csv').drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Feature emgineering and then split df in to X feature matrix and y target vector\n",
        "df['characters'] = df['tweet'].apply(lambda x : len(x))\n",
        "df['words'] = df['tweet'].apply(lambda x : len(x.split(' ')))\n",
        "X_train = df[['characters', 'words']]\n",
        "y_train = df['sentiment']\n",
        "\n",
        "df_test['characters'] = df['tweet'].apply(lambda x : len(x))\n",
        "df_test['words'] = df['tweet'].apply(lambda x : len(x.split(' ')))\n",
        "X_test = df_test[['characters', 'words']]\n",
        "y_test = df_test['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=28, max_samples=0.8, n_estimators=200,\n",
              "                       n_jobs=-1, random_state=98)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "#Initiate and train random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "modelrf = RandomForestClassifier(criterion='gini', random_state=98, max_depth=28, max_features='auto', n_jobs=-1, n_estimators=200, max_samples=.8)\n",
        "modelrf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4990375"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "#Score random forest classifier\n",
        "modelrf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV()"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "#Initiate and train logistic regression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "modellr = LogisticRegressionCV()\n",
        "modellr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49908125"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "#Score logistic regression\n",
        "modellr.score(X_test, y_test)"
      ]
    }
  ]
}